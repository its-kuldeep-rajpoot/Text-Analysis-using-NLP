{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8350efa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2371344",
   "metadata": {},
   "source": [
    "### Zipfiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ece0c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "157ea5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive words:  2007\n",
      "Negative words:  4784\n"
     ]
    }
   ],
   "source": [
    "master = \"MasterDictionary-20221105T045120Z-001.zip\"\n",
    "z = ZipFile(master)\n",
    "positive = str(z.read('MasterDictionary/positive-words.txt'))\n",
    "positive = positive.replace(\"\\\\n\",\" \")\n",
    "positive = positive.split()\n",
    "print(\"Positive words: \" ,len(positive))\n",
    "\n",
    "negative = str(z.read('MasterDictionary/negative-words.txt'))\n",
    "negative = negative.replace(\"\\\\n\",\" \")\n",
    "negative = negative.split()\n",
    "print(\"Negative words: \",len(negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a60ba41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words:  14236\n"
     ]
    }
   ],
   "source": [
    "stop_words = \"StopWords-20221105T045120Z-001.zip\"\n",
    "s = ZipFile(stop_words)\n",
    "s.infolist()\n",
    "\n",
    "stop01 = s.read('StopWords/StopWords_Generic.txt')\n",
    "stop02 = s.read('StopWords/StopWords_Currencies.txt')\n",
    "stop03 = s.read('StopWords/StopWords_Names.txt')\n",
    "stop04 = s.read('StopWords/StopWords_Geographic.txt')\n",
    "stop05 = s.read('StopWords/StopWords_GenericLong.txt')\n",
    "stop06 = s.read('StopWords/StopWords_Auditor.txt')\n",
    "stop07 = s.read('StopWords/StopWords_DatesandNumbers.txt')\n",
    "\n",
    "stop = stop01+stop02+stop03+stop04+stop05+stop06+stop07\n",
    "\n",
    "stop1 = stop.lower()\n",
    "stop1 = str(stop1)\n",
    "stop1 = stop1.replace(\"\\\\n\",\"\").replace(\"\\\\r\",\" \").replace(\"|\",\" \")\n",
    "stop1 = stop1.split()\n",
    "stop = stop1\n",
    "print(\"Stop words: \" ,len(stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f8d66",
   "metadata": {},
   "source": [
    "#### Data Frame to Store Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "637d7966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"URL_ID\",\"URL\",\"POSITIVE SCORE\",\"NEGATIVE SCORE\",\"POLARITY SCORE\",\"SUBJECTIVITY SCORE\",\"AVG SENTENCE LENGTH\",\"PERCENTAGE OF COMPLEX WORDS\",\"FOG INDEX\",\"AVG NUMBER OF WORDS PER SENTENCE\",\"COMPLEX WORD COUNT\",\"WORD COUNT\",\"SYLLABLE PER WORD\",\"PERSONAL PRONOUNS\",\"AVG WORD LENGTH\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b314c7c",
   "metadata": {},
   "source": [
    "### Url Text Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7501ce24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://insights.blackcoffer.com/challenges-and-opportunities-of-big-data-in-healthcare/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe1 = pd.read_excel('input.xlsx')\n",
    "dataframe1.iloc[113,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba015028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "u=0\n",
    "e=37\n",
    "while x<114:\n",
    "    url = dataframe1.iloc[x,1]\n",
    "    if x not in [7,20,107]:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:55.0) Gecko/20100101 Firefox/55.0',}\n",
    "\n",
    "        r = requests.get(url, headers=headers)\n",
    "        c = r.content\n",
    "\n",
    "        soup = BeautifulSoup(c, \"html.parser\")\n",
    "        title = soup.title.text.replace(\"- Blackcoffer Insights\", \"\")\n",
    "        title1 = title.lower()\n",
    "        title2 = title1.split()\n",
    "\n",
    "        para1 = soup.find(class_=\"td-post-content\").get_text().replace(\"\\n\",\" \").replace(\"\\xa0\", \"\")\n",
    "        para2 = para1.replace(\".\",\"\").replace(',','').replace(\"(\",\" \").replace(\")\",\" \")\n",
    "        para3 = para2.lower()\n",
    "        para4 = title2+para3.split()\n",
    "        #print(len(para4))\n",
    "\n",
    "        para_join = \" \".join(para4)\n",
    "        #para_join\n",
    "\n",
    "        ######### TO SAVE EXTRACTED ARTICLE IN TEXT FILE WITH UR_ID AS ITS NAME #########\n",
    "        text_file = open(\"C:/Users/drkdr/OneDrive/Desktop/Test Assignment (Black Coffer)/\"+str(e)+\".txt\",\"w\")\n",
    "\n",
    "        #write string to file\n",
    "        ti = title.split()\n",
    "        pa = para2.split()\n",
    "        para_join_text = ti+pa\n",
    "        normal_string=\" \".join(ch for ch in para_join_text if ch.isalnum())\n",
    "        text_file.write(normal_string)\n",
    "        #close file\n",
    "        text_file.close()\n",
    "        #-------------------------------------------------------------------------------#\n",
    "\n",
    "        para = word_tokenize(para_join)\n",
    "\n",
    "        para_t= para.copy()\n",
    "        #print(\"Total length: \",len(para_t))\n",
    "        i=0\n",
    "        while i < len(para_t)-1:\n",
    "            if para_t[i] in stop:\n",
    "                para_t.pop(i)\n",
    "            i+=1\n",
    "        paraf = para_t\n",
    "        #print(\"Length after excluding stop words: \",len(paraf))\n",
    "\n",
    "        words={}\n",
    "        i=0\n",
    "        while i < len(paraf)-1:\n",
    "            if paraf[i] in positive:\n",
    "                words[paraf[i]]=\"Positive\"\n",
    "            elif paraf[i] in negative:\n",
    "                words[paraf[i]]=\"Negative\"\n",
    "            i+=1\n",
    "        #print(\"Positive and Negative words in Para: \", len(words))\n",
    "\n",
    "        #1 - EXTRACTING DERIVED VARIABLES::\n",
    "        #-------------------------------------------------------------------------------#\n",
    "        p=0\n",
    "        n=0\n",
    "        for i in words:\n",
    "            if words[i]==\"Positive\":\n",
    "                p+=1\n",
    "            else:\n",
    "                n+=1\n",
    "        #print(\"2 - Positive Score: \", p)\n",
    "        #print(\"3 - Negative Score: \", n)\n",
    "\n",
    "        #Polarity Score = (Positive Score – Negative Score)/ ((Positive Score + Negative Score) + 0.000001)\n",
    "        #Ranges from -1 to +1\n",
    "\n",
    "        pol = (p-n)/((p+n)+0.000001)\n",
    "        #print(\"4 - Polarity Score: \", pol)\n",
    "\n",
    "        #Subjectivity Score = (Positive Score + Negative Score)/ ((Total Words after cleaning) + 0.000001)\n",
    "        #Ranges from 0 to 1\n",
    "\n",
    "        sub = (p+n)/((len(paraf))+0.000001)\n",
    "        #print(\"5 - Subjectivity Score: \", sub)\n",
    "        #-------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "        #2 - ANALYSIS OF READABILITY\n",
    "        #-------------------------------------------------------------------------------#\n",
    "        def count_syllables(word):\n",
    "            word = word.lower()\n",
    "            counter = 0\n",
    "            is_previous_vowel = False\n",
    "            if word[len(word)-2]==\"e\" and word[len(word)-1]==\"d\":\n",
    "                word=word.replace(\"ed\",\"\")\n",
    "            elif word[len(word)-2]==\"e\" and word[len(word)-1]==\"s\":\n",
    "                word=word.replace(\"es\",\"\")\n",
    "            for index, value in enumerate(word):\n",
    "                if value in [\"a\", \"e\", \"i\", \"o\", \"u\", \"y\"]:\n",
    "                    if index == len(word) - 1:\n",
    "                        if value == \"e\":\n",
    "                            if counter == 0:\n",
    "                                counter += 1\n",
    "                        else:\n",
    "                            counter += 1\n",
    "                    else:\n",
    "                        if is_previous_vowel == True:\n",
    "                            counter += 1\n",
    "                            is_previous_vowel = False\n",
    "                            break\n",
    "                    is_previous_vowel = True\n",
    "                else:\n",
    "                    if is_previous_vowel == True:\n",
    "                        counter += 1\n",
    "                    is_previous_vowel = False\n",
    "            return counter\n",
    "\n",
    "        #-------------------------------------------------------------------------------#\n",
    "        para_test = paraf.copy()\n",
    "        i=0\n",
    "        complex_words=[]\n",
    "        syllables = []\n",
    "        while i < len(para_test):\n",
    "            b=count_syllables(para_test[i])\n",
    "            syllables.append(b)\n",
    "            if b>2:\n",
    "                complex_words.append(para_test[i])\n",
    "            i+=1\n",
    "        len(syllables)\n",
    "        #-------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "        #4 - COMPLEX WORD COUNT::\n",
    "        #-------------------------------------------------------------------------------#\n",
    "        #print(\"Complex Word Count: \",len(complex_words))\n",
    "\n",
    "\n",
    "        para_sent = sent_tokenize(para1)\n",
    "\n",
    "        avg_sentence_length = len(para)/len(para_sent)\n",
    "        #print(\"6 - Average Sentence Length: \", avg_sentence_length)\n",
    "\n",
    "        complex_per = (len(complex_words)/len(para_test))*100\n",
    "        #print(\"7 - Percentage of complex words: \", complex_per)\n",
    "\n",
    "        fog_index = 0.4*(avg_sentence_length + complex_per)\n",
    "        #print(\"8 - Fog Index : \",fog_index)\n",
    "        #-------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "        #5 - WORD COUNT::\n",
    "        #-------------------------------------------------------------------------------#\n",
    "        text = para3\n",
    "        text_tokens = word_tokenize(text)\n",
    "        word_c = [word for word in text_tokens if not word in stopwords.words()]\n",
    "\n",
    "        #print(\"Removed all the stop words using stopwords class of nltk: Length=> \", len(word_c))\n",
    "\n",
    "        i=0\n",
    "        word_count=[]\n",
    "        while i < len(word_c):\n",
    "                if word_c[i]==\"?\":\n",
    "                    pass\n",
    "                elif word_c[i]==\".\":\n",
    "                    pass\n",
    "                elif word_c[i]==\",\":\n",
    "                    pass\n",
    "                elif word_c[i]==\"!\":\n",
    "                    pass\n",
    "                elif len(word_c[i])==1 and word_c[i] not in [\"a\",\"i\"]:\n",
    "                    pass\n",
    "                else:\n",
    "                    word_count.append(word_c[i])\n",
    "                i+=1\n",
    "\n",
    "        #print(\"After removing punctuations like (? ! , .) : Length => \", len(word_count))\n",
    "        #print(\"Word Count: \", len(word_count))\n",
    "        #-------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "        #6 - SYLLABLE COUNT PER WORD ::\n",
    "        #-------------------------------------------------------------------------------#\n",
    "\n",
    "        syllables1 = dict(zip(para_test,syllables))\n",
    "        syllables2 = sum(syllables)/len(word_count)\n",
    "        #print(\"Syllable per word : \", syllables2)\n",
    "        #print(\"Syllable Count Per Word : \",\"\\n\", syllables1)\n",
    "\n",
    "\n",
    "        #-------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "        #7- COUNTING PESRSONAL PRONOUNS :: ( “I,” “we,” “my,” “ours,” and “us” )\n",
    "        #-------------------------------------------------------------------------------#\n",
    "        import re\n",
    "        t = para3\n",
    "        pattern = re.compile('I')\n",
    "        matches = pattern.finditer(t)\n",
    "        I_count=0\n",
    "        for match in matches:\n",
    "            I_count+=1\n",
    "\n",
    "        pattern = re.compile('we')\n",
    "        matches = pattern.finditer(t)\n",
    "        we_count=0\n",
    "        for match in matches:\n",
    "            we_count+=1\n",
    "\n",
    "        pattern = re.compile('my')\n",
    "        matches = pattern.finditer(t)\n",
    "        my_count=0\n",
    "        for match in matches:\n",
    "            my_count+=1\n",
    "\n",
    "        pattern = re.compile('ours')\n",
    "        matches = pattern.finditer(t)\n",
    "        ours_count=0\n",
    "        for match in matches:\n",
    "            ours_count+=1\n",
    "\n",
    "        pattern = re.compile('us')\n",
    "        matches = pattern.finditer(t)\n",
    "        us_count=0\n",
    "        for match in matches:\n",
    "            us_count+=1\n",
    "        #\n",
    "        total_pronouns = I_count+we_count+my_count+ours_count+us_count\n",
    "        #print(\"Personal Pronouns: \",\"|I:\",I_count,\"|we:\",we_count,\"|my:\",my_count,\"|ours:\", ours_count,\"|us:\",us_count,\"|\")\n",
    "        #-------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "        #8 - AVERAGE WORD LENGTH::\n",
    "        #-------------------------------------------------------------------------------#\n",
    "        text_s = word_c\n",
    "        a=0\n",
    "        for i in text_s:\n",
    "            a=a+len(i)\n",
    "\n",
    "        #print(\"Sum of all characters in each word : \", a)\n",
    "\n",
    "        #print(\"Total number of words: \", len(word_c))\n",
    "\n",
    "        avg_word_length = a/len(word_c)\n",
    "\n",
    "        #print(\"Average Word Length : \", avg_word_length)\n",
    "\n",
    "        avg_words_per_sent = len(word_c)/len(para_sent)\n",
    "        #print(\"9 - Average Words Per Sentence : \", avg_words_per_sent)\n",
    "        #-------------------------------------------------------------------------------#\n",
    "\n",
    "        complex_words1 = len(complex_words)\n",
    "        word_count1 = len(word_count)\n",
    "\n",
    "        #print(\"\\n\")\n",
    "        #print(\"2  - POSITIVE SCORE: \", p)\n",
    "        #print(\"3  - NEGATIVE SCORE: \", n)\n",
    "        #print(\"4  - POLARITY SCORE: \", pol)\n",
    "        #print(\"5  - SUBJECTIVITY SCORE: \", sub)\n",
    "        #print(\"6  - AVERAGE SENTENCE LENGTH: \", avg_sentence_length)\n",
    "        #print(\"7  - PERCENTAGE OF COMPLEX WORDS: \", complex_per)\n",
    "        #print(\"8  - FOG INDEX : \",fog_index)\n",
    "        #print(\"9  - AVG NUMBER OF WORDS PER SENTENCE : \", avg_words_per_sent)\n",
    "        #print(\"10 - COMPLEX WORD COUNT : \", complex_words1)\n",
    "        #print(\"11 - WORD COUNT : \", word_count1)\n",
    "        #print(\"12 - SYLLABLE PER WORD : \", syllables2)\n",
    "        #print(\"13 - PERSONAL PRONOUNS : \", total_pronouns)\n",
    "        #print(\"14 - AVG WORD LENGTH : \", avg_word_length)\n",
    "\n",
    "\n",
    "        list_variables = [e, url, p, n, pol, sub, avg_sentence_length, complex_per, fog_index, avg_words_per_sent, complex_words1, word_count1, syllables2, total_pronouns, avg_word_length]\n",
    "        #print(list_variables)\n",
    "\n",
    "        df.loc[u]=list_variables\n",
    "\n",
    "    else:\n",
    "        list_na = [e,url,\"Invalid URL\",\"Invalid URL\",\"Invalid URL\",\"Invalid URL\",\"Invalid URL\",\"Invalid URL\",\"Invalid URL\",\"Invalid URL\",\"Invalid URL\",\"Invalid URL\",\"Invalid URL\",\"Invalid URL\",\"Invalid URL\",]\n",
    "        df.loc[u]=list_na\n",
    "    \n",
    "    print(x,\" of 113\")\n",
    "    u+=1\n",
    "    e+=1\n",
    "    x+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a83eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1ccbc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>46</td>\n",
       "      <td>25</td>\n",
       "      <td>0.295775</td>\n",
       "      <td>0.058101</td>\n",
       "      <td>23.74026</td>\n",
       "      <td>29.214403</td>\n",
       "      <td>21.181865</td>\n",
       "      <td>13.246753</td>\n",
       "      <td>357</td>\n",
       "      <td>999</td>\n",
       "      <td>2.393393</td>\n",
       "      <td>56</td>\n",
       "      <td>7.530392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>39</td>\n",
       "      <td>29</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.07489</td>\n",
       "      <td>18.4375</td>\n",
       "      <td>17.84141</td>\n",
       "      <td>14.511564</td>\n",
       "      <td>7.6625</td>\n",
       "      <td>162</td>\n",
       "      <td>576</td>\n",
       "      <td>2.579861</td>\n",
       "      <td>36</td>\n",
       "      <td>6.76509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>48</td>\n",
       "      <td>25</td>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.064716</td>\n",
       "      <td>20.529412</td>\n",
       "      <td>27.659574</td>\n",
       "      <td>19.275594</td>\n",
       "      <td>10.411765</td>\n",
       "      <td>312</td>\n",
       "      <td>859</td>\n",
       "      <td>2.563446</td>\n",
       "      <td>61</td>\n",
       "      <td>7.450847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.056405</td>\n",
       "      <td>17.8</td>\n",
       "      <td>17.686424</td>\n",
       "      <td>14.19457</td>\n",
       "      <td>7.568421</td>\n",
       "      <td>185</td>\n",
       "      <td>689</td>\n",
       "      <td>2.516691</td>\n",
       "      <td>60</td>\n",
       "      <td>6.783032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.053037</td>\n",
       "      <td>23.088608</td>\n",
       "      <td>21.12917</td>\n",
       "      <td>17.687111</td>\n",
       "      <td>11.113924</td>\n",
       "      <td>247</td>\n",
       "      <td>820</td>\n",
       "      <td>2.454878</td>\n",
       "      <td>65</td>\n",
       "      <td>6.817768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL POSITIVE SCORE  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...             46   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...             39   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...             48   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...             37   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...             37   \n",
       "\n",
       "  NEGATIVE SCORE POLARITY SCORE SUBJECTIVITY SCORE AVG SENTENCE LENGTH  \\\n",
       "0             25       0.295775           0.058101            23.74026   \n",
       "1             29       0.147059            0.07489             18.4375   \n",
       "2             25       0.315068           0.064716           20.529412   \n",
       "3             22       0.254237           0.056405                17.8   \n",
       "4             25       0.193548           0.053037           23.088608   \n",
       "\n",
       "  PERCENTAGE OF COMPLEX WORDS  FOG INDEX AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                   29.214403  21.181865                        13.246753   \n",
       "1                    17.84141  14.511564                           7.6625   \n",
       "2                   27.659574  19.275594                        10.411765   \n",
       "3                   17.686424   14.19457                         7.568421   \n",
       "4                    21.12917  17.687111                        11.113924   \n",
       "\n",
       "  COMPLEX WORD COUNT WORD COUNT SYLLABLE PER WORD PERSONAL PRONOUNS  \\\n",
       "0                357        999          2.393393                56   \n",
       "1                162        576          2.579861                36   \n",
       "2                312        859          2.563446                61   \n",
       "3                185        689          2.516691                60   \n",
       "4                247        820          2.454878                65   \n",
       "\n",
       "  AVG WORD LENGTH  \n",
       "0        7.530392  \n",
       "1         6.76509  \n",
       "2        7.450847  \n",
       "3        6.783032  \n",
       "4        6.817768  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6efeeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"Final Output Submission.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6e61e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
